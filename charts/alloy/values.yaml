## @section Global parameters
## Global Docker image parameters
## Please, note that this will override the image parameters, including dependencies, configured to use the global value
## Current available global Docker image parameters: imageRegistry, imagePullSecrets and storageClass
##

## @param global.imageRegistry Global Docker image registry
## @param global.imagePullSecrets Global Docker registry secret names as an array
## @param global.storageClass Global StorageClass for Persistent Volume(s)
##
global:
  imageRegistry: ""
  ## E.g.
  ## imagePullSecrets:
  ##   - myRegistryKeySecretName
  ##
  imagePullSecrets: []
  storageClass: ""

## @section Common parameters
##
## @param nameOverride String to partially override common.names.name
##
nameOverride: ""
## @param fullnameOverride String to fully override common.names.fullname
##
fullnameOverride: ""
## @param commonLabels Labels to add to all deployed objects
##
commonLabels: {}
## @param commonAnnotations Annotations to add to all deployed objects
##
commonAnnotations: {}
## Diagnostic mode
## @param diagnosticMode.enabled Enable diagnostic mode (all probes will be disabled and the command will be overridden)
## @param diagnosticMode.command Command to override all containers in the chart release
## @param diagnosticMode.args Args to override all containers in the chart release
##
diagnosticMode:
  enabled: false
  command:
    - sleep
  args:
    - infinity

## @section alloy Parameters
##

## %%MAIN_CONTAINER/POD_DESCRIPTION%%
##
alloy:
  ## @param alloy.pod Pod configuration
  ## @param alloy.pod.enabled Run %%MAIN_CONTAINER%% as a Pod rather than a Deployment
  ## @param alloy.pod.restartPolicy %%MAIN_CONTAINER%% pod container restart policy.
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy
  ##
  pod:
    enabled: true
    restartPolicy: Never
  ## @param alloy.hostNetwork Specify if host network should be enabled for alloy pod
  ##
  hostNetwork: true
  ## @param alloy.dnsConfig  Allows users more control on the DNS settings for a Pod.
  ## Ref: https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#pod-dns-config
  ## E.g.
  ## dnsConfig:
  ##   nameservers:
  ##     - 192.0.2.1 # this is an example
  ##   searches:
  ##     - ns1.svc.cluster-domain.example
  ##     - my.dns.search.suffix
  ##   options:
  ##     - name: ndots
  ##       value: "2"
  ##     - name: edns0
  ##
  dnsConfig: {}
  ## @param alloy.dnsPolicy Deployment pod DNS policy
  ## ref: https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/
  ## E.g.
  ## dnsPolicy: ClusterFirstWithHostNet
  ##
  dnsPolicy: ""
  ## grafana alloy image
  ## ref: https://hub.docker.com/r/grafana/alloy/tags
  ## @param alloy.image.registry alloy image registry
  ## @param alloy.image.repository alloy image repository
  ## @param alloy.image.tag alloy image tag (immutable tags are recommended)
  ## @param alloy.image.digest alloy image digest in the way sha256:aa.... Please note this parameter, if set, will override the tag image tag (immutable tags are recommended)
  ## @param alloy.image.pullPolicy alloy image pull policy
  ## @param alloy.image.pullSecrets alloy image pull secrets
  ##
  image:
    registry: docker.io
    repository: grafana/alloy
    tag: v1.12.2
    digest: ""
    ## Specify a imagePullPolicy
    ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'
    ## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images
    ##
    pullPolicy: IfNotPresent
    ## Optionally specify an array of imagePullSecrets.
    ## Secrets must be manually created in the namespace.
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
    ## e.g:
    ## pullSecrets:
    ##   - myRegistryKeySecretName
    ##
    pullSecrets: []
  ## @param alloy.containerPorts alloy container port to expose to host
  ## e.g.
  ## containerPorts:
  ##   - name: http
  ##     containerPort: 80
  ##     hostPort: 80
  ##     hostIP: 192.168.255.10
  ##     protocol: TCP
  ##   - name: https
  ##     containerPort: 443
  ##     hostPort: 443
  ##     hostIP: 192.168.255.10
  ##     protocol: TCP
  ##
  containerPorts: {}
  ## Configure extra options for alloy containers' liveness and readiness probes
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes
  ## @param alloy.livenessProbe.enabled Enable livenessProbe on alloy containers
  ## @param alloy.livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe
  ## @param alloy.livenessProbe.periodSeconds Period seconds for livenessProbe
  ## @param alloy.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
  ## @param alloy.livenessProbe.failureThreshold Failure threshold for livenessProbe
  ## @param alloy.livenessProbe.successThreshold Success threshold for livenessProbe
  ##
  livenessProbe:
    enabled: false
    initialDelaySeconds: foo
    periodSeconds: bar
    timeoutSeconds: foo
    failureThreshold: bar
    successThreshold: foo
  ## @param alloy.readinessProbe.enabled Enable readinessProbe on alloy containers
  ## @param alloy.readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe
  ## @param alloy.readinessProbe.periodSeconds Period seconds for readinessProbe
  ## @param alloy.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
  ## @param alloy.readinessProbe.failureThreshold Failure threshold for readinessProbe
  ## @param alloy.readinessProbe.successThreshold Success threshold for readinessProbe
  ## note: podman not support readinessProbe currently
  ##
  readinessProbe:
    enabled: false
    initialDelaySeconds: foo
    periodSeconds: bar
    timeoutSeconds: foo
    failureThreshold: bar
    successThreshold: foo
  ## @param alloy.startupProbe.enabled Enable startupProbe on alloy containers
  ## @param alloy.startupProbe.initialDelaySeconds Initial delay seconds for startupProbe
  ## @param alloy.startupProbe.periodSeconds Period seconds for startupProbe
  ## @param alloy.startupProbe.timeoutSeconds Timeout seconds for startupProbe
  ## @param alloy.startupProbe.failureThreshold Failure threshold for startupProbe
  ## @param alloy.startupProbe.successThreshold Success threshold for startupProbe
  ##
  startupProbe:
    enabled: false
    initialDelaySeconds: foo
    periodSeconds: bar
    timeoutSeconds: foo
    failureThreshold: bar
    successThreshold: foo
  ## @param alloy.customLivenessProbe Custom livenessProbe that overrides the default one
  ##
  customLivenessProbe: {}
  ## @param alloy.customReadinessProbe Custom readinessProbe that overrides the default one
  ##
  customReadinessProbe: {}
  ## @param alloy.customStartupProbe Custom startupProbe that overrides the default one
  ##
  customStartupProbe: {}
  ## alloy resource requests and limits
  ## ref: http://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
  ## @param alloy.resourcesPreset Set alloy container resources according to one common preset (allowed values: none, nano, micro, small, medium, large, xlarge, 2xlarge). This is ignored if alloy.resources is set (alloy.resources is recommended for production).
  ## More information: https://github.com/bitnami/charts/blob/main/bitnami/common/templates/_resources.tpl#L15
  ##
  resourcesPreset: "micro"
  ## @param alloy.resources Set alloy container requests and limits for different resources like CPU or memory (essential for production workloads)
  ## Example:
  ## resources:
  ##   requests:
  ##     cpu: 2
  ##     memory: 512Mi
  ##   limits:
  ##     cpu: 3
  ##     memory: 1024Mi
  ##
  resources: {}
  ## Configure Pods Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
  ## @param alloy.podSecurityContext.enabled Enabled alloy pods' Security Context
  ## @param alloy.podSecurityContext.fsGroup Set alloy pod's Security Context fsGroup
  ## note: podman kube play does not support fsGroup yet
  ##
  podSecurityContext:
    enabled: false
    # fsGroup: 1001
  ## Configure Container Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container
  ## @param alloy.containerSecurityContext.enabled Enabled alloy containers' Security Context
  ## @param alloy.containerSecurityContext.runAsUser Set alloy containers' Security Context runAsUser
  ## @param alloy.containerSecurityContext.runAsNonRoot Set alloy containers' Security Context runAsNonRoot
  ## @param alloy.containerSecurityContext.readOnlyRootFilesystem Set alloy containers' Security Context runAsNonRoot
  ##
  containerSecurityContext:
    enabled: true
    runAsUser: 473
    runAsGroup: 473
    runAsNonRoot: true
    readOnlyRootFilesystem: false
    privileged: false

  # %%OTHER_PARAMETERS_RELATED_TO_THIS_CONTAINER/POD%%
  ## @param alloy.config alloy configuration which will host in /etc/alloy/config.alloy
  ##
  config:
    ## @param alloy.config.fromYAML alloy configuration convert from yaml
    ## component: https://grafana.com/docs/alloy/latest/get-started/configuration-syntax/components/
    ## ref: https://github.com/grafana/alloy/blob/v1.12.2/example-config.alloy
    ## e.g.
    ## follow values:
    ## - component: logging
    ##   attributes:
    ##     level: debug
    ##     format: logfmt
    ##
    ## will convert to:
    ## logging {
    ##   level  = "debug"
    ##   format = "logfmt"
    ## }
    ## ---
    ## follow values:
    ## - component: otelcol.exporter.otlp
    ##   label: tempo
    ##   attributes:
    ##     client:
    ##       endpoint: '"localhost:4317"'
    ##       tls:
    ##         insecure: true
    ##
    ## will convert to:
    ## otelcol.exporter.otlp "tempo" {
    ##   client {
    ##     endpoint = "localhost:4317"
    ##     tls {
    ##       insecure = true
    ##     }
    ##   }
    ## }
    ## ---
    ## follow values:
    ## - component: loki.relabel
    ##   label: journal
    ##   attributes:
    ##     forward_to: []
    ##     rule.0:
    ##       source_labels:
    ##         - '"__journal__systemd_unit"'
    ##       target_label: '"systemd_unit"'
    ##     rule.1:
    ##       source_labels:
    ##         - '"__journal__hostname"'
    ##       target_label: '"systemd_hostname"'
    ##     rule.2:
    ##       source_labels:
    ##         - '"__journal__transport"'
    ##       target_label: '"systemd_transport"'
    ##
    ## will convert to
    ## loki.relabel "journal" {
    ##   forward_to = []
    ##   rule {
    ##     source_labels = ["__journal__systemd_unit"]
    ##     target_label  = "systemd_unit"
    ##   }
    ##   rule {
    ##     source_labels = ["__journal__hostname"]
    ##     target_label = "systemd_hostname"
    ##   }
    ##   rule {
    ##     source_labels = ["__journal__transport"]
    ##     target_label = "systemd_transport"
    ##   }
    ## }
    ##
    fromYAML:
      - component: logging
        attributes:
          level: debug
          format: logfmt
      # - component: tracing
      #   attributes:
      #     sampling_fraction: 1
      #     write_to:
      #       - otelcol.exporter.otlp.tempo.input
      # - component: otelcol.exporter.otlp
      #   label: tempo
      #   attributes:
      #     client:
      #       endpoint: '"localhost:4317"'
      #       tls:
      #         insecure: true
      # - component: prometheus.exporter.unix
      #   label: default
      #   attributes: {}
      # - component: prometheus.scrape
      #   label: default
      #   attributes:
      #     targets:
      #       # prometheus.exporter.unix.default.targets
      #       - '"__address__"': prometheus.exporter.unix.default.targets
      #       - '"__address__"': '"localhost:9001"'
      #     forward_to:
      #       - prometheus.remote_write.default.receiver
      #     scrape_config:
      #       job_name: '"default"'
      # - component: loki.relabel
      #   label: journal
      #   attributes:
      #     forward_to: []
      #     rule.0:
      #       source_labels:
      #         - '"__journal__systemd_unit"'
      #         - '"__journal__systemd_unit"'
      #       target_label: '"systemd_unit"'
      #     rule.1:
      #       source_labels:
      #         - '"__journal__hostname"'
      #       target_label: '"systemd_hostname"'
      #     rule.2:
      #       source_labels:
      #         - '"__journal__transport"'
      #       target_label: '"systemd_transport"'
      # - component: prometheus.remote_write
      #   label: default
      #   attributes:
      #     endpoint:
      #       url: '"http://localhost:9009/api/prom/push"'
    ## @param alloy.config.fromPlanText put content directly from below block
    ##
    fromPlanText: # |-
    #   loki.relabel "journal" {
    #     forward_to = []
    #     rule {
    #       source_labels = ["__journal__systemd_unit"]
    #       target_label  = "systemd_unit"
    #     }
    #     rule {
    #       source_labels = ["__journal__hostname"]
    #       target_label = "systemd_hostname"
    #     }
    #     rule {
    #       source_labels = ["__journal__transport"]
    #       target_label = "systemd_transport"
    #     }
    #   }

  ## @param alloy.secret secret pass to the container
  ##
  secret:
    ## @param alloy.secret.envVars secret content pass to container via environment variable
    ## e.g.
    ## envVars:
    ##   SECRET_KEY1: secret_value1
    ##   SECRET_KEY2: secret_value2
    ##
    envVars: {}
    ## @param alloy.secret.tls secret setting of cert and key or whatever tls content will set in the container
    ##
    tls:
      ## @param alloy.secret.tls.mountPath secret mount path (dir) setting of cert and key or whatever tls content will set in the container
      ## this config should match with config under grafana.configFile.server.cert_key and grafana.configFile.server.cert_file if any
      ##
      mountPath: /etc/alloy/certs
      ## @param alloy.secret.tls.contents secret content of cert and key or whatever tls content will set in the container
      ## You can set the content key as whatever file name you like
      ## But the tls set in configFiles above must match with the settings here
      ## key and certificate should start with -----BEGIN CERTIFICATE----- or -----BEGIN RSA PRIVATE KEY-----
      ## e.g.
      ## contents:
      ##  ca.crt: ""
      ##  alloy.crt: ""
      ##  alloy.key: ""
      ##
      contents: {}

  ## @param alloy.existingConfigmap The name of an existing ConfigMap with your custom configuration for alloy
  ##
  existingConfigmap:
  ## @param alloy.command Override default container command (useful when using custom images)
  ##
  command: []
  ## @param alloy.flags flags for `alloy run` command
  ## ref: https://grafana.com/docs/alloy/v1.11/reference/cli/run/
  ##
  flags:
    server:
      http:
        ## @param alloy.flags.server.http.enable-pprof Enable /debug/pprof profiling endpoints. (default true).
        ##
        enable-pprof: true
        ## @param alloy.flags.server.http.memory-addr Address to listen for in-memory HTTP traffic on (default alloy.internal:12345).
        ##
        memory-addr: alloy.internal:12345
        ## @param alloy.flags.server.http.listen-addr: Address to listen for HTTP traffic on (default 127.0.0.1:12345).
        ##
        listen-addr: 127.0.0.1:12345
        ## @param alloy.flags.
        ##
        ui-path-prefix: /
    storage:
      ## @param alloy.flags.storage.path Base directory where components can store data (default data-alloy/).
      ##
      path: /var/lib/alloy/data
    ## @param alloy.flags.disable-reporting Disable data collection (default false).
    ##
    # disable-reporting:
    ## @param alloy.flags.disable-support-bundle Disable support bundle endpoint (default false)
    ##
    # disable-support-bundle:
    cluster:
      ## @param alloy.flags.cluster.enabled Start Alloy in clustered mode (default false).
      ##
      enabled: false
      ## @param alloy.flags.cluster.node-name The name to use for this node (defaults to the environmentâ€™s hostname).
      ##
      node-name: null
      ## @param alloy.flags.cluster.join-addresses Comma-separated list of addresses to join the cluster at (default "").
      ## Mutually exclusive with --cluster.discover-peers.
      ##
      join-addresses: null
      ## @param alloy.flags.cluster.discover-peers List of key-value tuples for discovering peers (default "").
      ## Mutually exclusive with --cluster.join-addresses.
      ##
      discover-peers: null
      ## @param alloy.flags.cluster.rejoin-interval How often to rejoin the list of peers (default "60s").
      ##
      rejoin-interval: 60s
      ## @param alloy.flags.cluster.advertise-address Address to advertise to other cluster nodes (default "").
      ##
      advertise-address: null
      ## @param alloy.flags.cluster.advertise-interfaces List of interfaces used to infer an address to advertise. Set to all to use all available network interfaces on the system. (default "eth0,en0").
      ##
      advertise-interfaces: eth0,en0
      ## @param alloy.flags.cluster.max-join-peers Number of peers to join from the discovered set (default 5).
      ##
      max-join-peers: 5
      ## @param alloy.flags.cluster.name Name to prevent nodes without this identifier from joining the cluster (default "").
      ##
      name: null
      ## @param alloy.flags.cluster.enable-tls Specifies whether TLS should be used for communication between peers (default false).
      ##
      enable-tls: false
      ## @param alloy.flags.cluster.tls-ca-path: Path to the CA certificate file used for peer communication over TLS.
      ##
      tls-ca-path: null
      ## @param alloy.flags.cluster.tls-key-path: Path to the key file used for peer communication over TLS.
      ##
      tls-key-path: null
      ## @param alloy.flags.cluster.tls-server-name: Server name used for peer communication over TLS.
      ##
      tls-server-name: null
      ## @param alloy.flags.cluster.wait-for-size: Wait for the cluster to reach the specified number of instances before allowing components that use clustering to begin processing. Zero means disabled (default 0).
      ##
      wait-for-size: 0
      ## @param alloy.flags.cluster.wait-timeout: Maximum duration to wait for minimum cluster size before proceeding with available nodes. Zero means wait forever, no timeout (default 0).
      ##
      wait-timeout: 0
    config:
      ## @param alloy.flags.config.format: The format of the source file. Supported formats: alloy, otelcol, prometheus, promtail, static (default "alloy").
      ##
      format: alloy
      ## @param alloy.flags.config.bypass-conversion-errors: Enable bypassing errors when converting (default false).
      ##
      bypass-conversion-errors: false
      ## @param alloy.flags.config.extra-args: Extra arguments from the original format used by the converter.
      ##
      extra-args:
    stability:
      ## @param alloy.flags.stability.level: The minimum permitted stability level of functionality to run. Supported values: experimental, public-preview, generally-available (default "generally-available").
      ##
      level: generally-available
    feature:
      community-components:
        ## @param alloy.flags.feature.community-components.enabled: Enable community components (default false).
        ##
        enabled: false
  ## @param alloy.args Override default container args (useful when using custom images)
  ##
  args: '{{ print "- run\n- /etc/alloy/config.alloy\n" }} {{- include "processFlags" (dict "values" .Values.alloy.flags) | trim -}}"'
  ## @param alloy.automountServiceAccountToken Mount Service Account token in alloy pods
  ##
  automountServiceAccountToken: false
  ## @param alloy.hostAliases alloy pods host aliases
  ## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/
  ##
  hostAliases: []
  ## @param alloy.deploymentAnnotations Annotations for alloy deployment
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
  ##
  deploymentAnnotations: {}
  ## @param alloy.podLabels Extra labels for alloy pods
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
  ##
  podLabels: {}
  ## @param alloy.podAnnotations Annotations for alloy pods
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
  ##
  podAnnotations:
    io.podman.annotations.userns: keep-id:uid=473,gid=473
  ## @param alloy.podAffinityPreset Pod affinity preset. Ignored if `alloy.affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAffinityPreset: ""
  ## @param alloy.podAntiAffinityPreset Pod anti-affinity preset. Ignored if `alloy.affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAntiAffinityPreset: soft
  ## Node alloy.affinity preset
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  ##
  nodeAffinityPreset:
    ## @param alloy.nodeAffinityPreset.type Node affinity preset type. Ignored if `alloy.affinity` is set. Allowed values: `soft` or `hard`
    ##
    type: ""
    ## @param alloy.nodeAffinityPreset.key Node label key to match. Ignored if `alloy.affinity` is set
    ##
    key: ""
    ## @param alloy.nodeAffinityPreset.values Node label values to match. Ignored if `alloy.affinity` is set
    ## E.g.
    ## values:
    ##   - e2e-az1
    ##   - e2e-az2
    ##
    values: []
  ## @param alloy.affinity Affinity for alloy pods assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  ## NOTE: `alloy.podAffinityPreset`, `alloy.podAntiAffinityPreset`, and `alloy.nodeAffinityPreset` will be ignored when it's set
  ##
  affinity: {}
  ## @param alloy.nodeSelector Node labels for alloy pods assignment
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/
  ##
  nodeSelector: {}
  ## @param alloy.tolerations Tolerations for alloy pods assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  ##
  tolerations: []
  ## ONLY FOR DEPLOYMENTS:
  ## @param alloy.updateStrategy.type alloy deployment strategy type
  ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy
  ## ONLY FOR STATEFULSETS:
  ## @param alloy.updateStrategy.type alloy statefulset strategy type
  ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
  ##
  updateStrategy:
    ## ONLY FOR DEPLOYMENTS:
    ## Can be set to RollingUpdate or Recreate
    ## ONLY FOR STATEFULSETS:
    ## Can be set to RollingUpdate or OnDelete
    ##
    type: RollingUpdate
  ## @param alloy.priorityClassName alloy pods' priorityClassName
  ##
  priorityClassName: ""
  ## @param alloy.topologySpreadConstraints Topology Spread Constraints for alloy pod assignment spread across your cluster among failure-domains
  ## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/#spread-constraints-for-pods
  ##
  topologySpreadConstraints: []
  ## @param alloy.schedulerName Name of the k8s scheduler (other than default) for alloy pods
  ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
  ##
  schedulerName: ""
  ## @param alloy.terminationGracePeriodSeconds Seconds alloy pods need to terminate gracefully
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods
  ##
  terminationGracePeriodSeconds: ""
  ## @param alloy.lifecycleHooks for alloy containers to automate configuration before or after startup
  ##
  lifecycleHooks: {}
  ## @param alloy.extraEnvVars Array with extra environment variables to add to alloy containers
  ## e.g:
  ## extraEnvVars:
  ##   - name: FOO
  ##     value: "bar"
  ##
  extraEnvVars: []
  ## @param alloy.extraEnvVarsCM Name of existing ConfigMap containing extra env vars for alloy containers
  ##
  extraEnvVarsCM: ""
  ## @param alloy.extraEnvVarsSecret Name of existing Secret containing extra env vars for alloy containers
  ##
  extraEnvVarsSecret: ""
  ## @param alloy.extraVolumes Optionally specify extra list of additional volumes for the alloy pods
  ##
  extraVolumes: []
  ## @param alloy.extraVolumeMounts Optionally specify extra list of additional volumeMounts for the alloy containers
  ##
  extraVolumeMounts: []
  ## @param alloy.sidecars Add additional sidecar containers to the alloy pods
  ## e.g:
  ## sidecars:
  ##   - name: your-image-name
  ##     image: your-image
  ##     imagePullPolicy: Always
  ##     ports:
  ##       - name: portname
  ##         containerPort: 1234
  ##
  sidecars: []
  ## @param alloy.initContainers Add additional init containers to the alloy pods
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
  ## e.g:
  ## initContainers:
  ##  - name: your-image-name
  ##    image: your-image
  ##    imagePullPolicy: Always
  ##    command: ['sh', '-c', 'echo "hello world"']
  ##
  initContainers: []

## @section Persistence Parameters
##

## Enable persistence using Persistent Volume Claims
## ref: https://kubernetes.io/docs/concepts/storage/persistent-volumes/
##
persistence:
  ## @param persistence.enabled Enable persistence using Persistent Volume Claims
  ##
  enabled: true
  ## @param persistence.mountPath Path to mount the volume at.
  ##
  mountPath: "{{ .Values.alloy.flags.storage.path }}"
  ## @param persistence.subPath The subdirectory of the volume to mount to, useful in dev environments and one PV for multiple services
  ##
  subPath: ""
  ## @param persistence.storageClass Storage class of backing PVC
  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  ##
  storageClass: ""
  ## @param persistence.annotations Persistent Volume Claim annotations
  ##
  annotations: {}
  ## @param persistence.accessModes Persistent Volume Access Modes
  ##
  accessModes:
    - ReadWriteOnce
  ## @param persistence.size Size of data volume
  ##
  size: 8Gi
  ## @param persistence.dataSource Custom PVC data source
  ##
  dataSource: {}
  ## @param persistence.existingClaim The name of an existing PVC to use for persistence
  ##
  existingClaim: ""
  ## @param persistence.selector Selector to match an existing Persistent Volume for alloy data PVC
  ## If set, the PVC can't have a PV dynamically provisioned for it
  ## E.g.
  ## selector:
  ##   matchLabels:
  ##     app: my-app
  ##
  selector: {}
## @section Init Container Parameters
##

## @section Default init containers Parameters

defaultInitContainers:
  ## 'volume-permissions' init container
  ## Changes the owner and group of the persistent volume mount(s) point(s) to runAsUser:fsGroup values
  ##   based on the *podSecurityContext/*containerSecurityContext parameters
  ##
  volumePermissions:
    ## @param defaultInitContainers.volumePermissions.enabled Enable init container that adapts the owner/group of the PV mount(s) point(s)
    ##
    enabled: false
    ## OS Shell + Utility image
    ## ref: https://hub.docker.com/r/bitnami/os-shell
    ## @param defaultInitContainers.volumePermissions.image.registry [default: REGISTRY_NAME] "volume-permissions" init-containers' image registry
    ## @param defaultInitContainers.volumePermissions.image.repository [default: REPOSITORY_NAME/os-shell] "volume-permissions" init-containers' image repository
    ## @skip defaultInitContainers.volumePermissions.image.tag "volume-permissions" init-containers' image tag (immutable tags are recommended)
    ## @param defaultInitContainers.volumePermissions.image.digest "volume-permissions" init-containers' image digest in the way sha256:aa.... Please note this parameter, if set, will override the tag
    ## @param defaultInitContainers.volumePermissions.image.pullPolicy "volume-permissions" init-containers' image pull policy
    ## @param defaultInitContainers.volumePermissions.image.pullSecrets "volume-permissions" init-containers' image pull secrets
    ##
    image:
      registry: docker.io
      repository: bitnami/os-shell
      tag: 12-debian-12-r46
      digest: ""
      pullPolicy: IfNotPresent
      ## Optionally specify an array of imagePullSecrets.
      ## Secrets must be manually created in the namespace.
      ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
      ## Example:
      ## pullSecrets:
      ##   - myRegistryKeySecretName
      ##
      pullSecrets: []
    ## Configure "volume-permissions" init-container Security Context
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container
    ## @param defaultInitContainers.volumePermissions.containerSecurityContext.enabled Enabled "volume-permissions" init-containers' Security Context
    ## @param defaultInitContainers.volumePermissions.containerSecurityContext.seLinuxOptions [object,nullable] Set SELinux options in "volume-permissions" init-containers
    ## @param defaultInitContainers.volumePermissions.containerSecurityContext.runAsUser Set runAsUser in "volume-permissions" init-containers' Security Context
    ## NOTE: when runAsUser is set to special value "auto", init container will try to chown the
    ##   data folder to auto-determined user&group, using commands: `id -u`:`id -G | cut -d" " -f2`
    ##   "auto" is especially useful for OpenShift which has scc with dynamic user ids (and 0 is not allowed)
    ## @param defaultInitContainers.volumePermissions.containerSecurityContext.privileged Set privileged in "volume-permissions" init-containers' Security Context
    ## @param defaultInitContainers.volumePermissions.containerSecurityContext.allowPrivilegeEscalation Set allowPrivilegeEscalation in "volume-permissions" init-containers' Security Context
    ## @param defaultInitContainers.volumePermissions.containerSecurityContext.capabilities.add List of capabilities to be added in "volume-permissions" init-containers
    ## @param defaultInitContainers.volumePermissions.containerSecurityContext.capabilities.drop List of capabilities to be dropped in "volume-permissions" init-containers
    ## @param defaultInitContainers.volumePermissions.containerSecurityContext.seccompProfile.type Set seccomp profile in "volume-permissions" init-containers
    ##
    containerSecurityContext:
      enabled: true
      seLinuxOptions: {}
      runAsUser: 0
      privileged: false
      allowPrivilegeEscalation: false
      capabilities:
        add: []
        drop: ["ALL"]
      seccompProfile:
        type: "RuntimeDefault"
    ## "volume-permissions" init container resource requests and limits
    ## ref: http://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
    ## @param defaultInitContainers.volumePermissions.resourcesPreset Set "volume-permissions" init container resources according to one common preset (allowed values: none, nano, micro, small, medium, large, xlarge, 2xlarge). This is ignored if defaultInitContainers.volumePermissions.resources is set (defaultInitContainers.volumePermissions.resources is recommended for production).
    ## More information: https://github.com/bitnami/charts/blob/main/bitnami/common/templates/_resources.tpl#L15
    ##
    resourcesPreset: "nano"
    ## @param defaultInitContainers.volumePermissions.resources Set "volume-permissions" init container requests and limits for different resources like CPU or memory (essential for production workloads)
    ## E.g:
    ## resources:
    ##   requests:
    ##     cpu: 2
    ##     memory: 512Mi
    ##   limits:
    ##     cpu: 3
    ##     memory: 1024Mi
    ##
    resources: {}

## @section Other Parameters
##

## ServiceAccount configuration
## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/
##
serviceAccount:
  ## @param serviceAccount.name The name of the ServiceAccount to use.
  ## If not set and create is true, a name is generated using the common.names.fullname template
  ##
  name: ""

## %%SUBCHART_CONTAINER/POD_DESCRIPTION%%
##
# %%SUBCHART_NAME%%:
SUBCHART_NAME:
  enabled: false
  # %%OTHER_PARAMETERS_RELATED_TO_THIS_SUBCHART%%
